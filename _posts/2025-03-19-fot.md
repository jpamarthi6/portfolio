---
layout: post
title: 'Designing Task-Centered HMI Strategies for Human-AI Collaboration'
# permalink: /FOT/
---
#### Designing Task-Centered HMI Strategies for Human-AI Collaboration
---
{: data-content="hr with text"}
### Overview:

As Level 4 autonomous trucks become a reality, how do we decide what tasks still need a human—and how do we communicate those through interface design? Over 3 months, I led a research project to map automation gaps and design better HMIs for safe, explainable, and collaborative human-machine interaction in trucking.

---
{: data-content="hr with text"}
### Problem:

The trucking industry is advancing rapidly, but there's limited guidance on how to split responsibilities between humans and automation—or how to reflect that in HMI design. Our goal: identify key tasks that still need human input and design HMI strategies that foster trust and clarity.

---
{: data-content="hr with text"}
### Users:

- **Primary:** Truck drivers using L4 autonomous systems
- **Secondary:** HMI designers, AV companies, safety regulators

---
{: data-content="hr with text"}
### My Role:

I led the project end to end—research planning, scoping review, CDL task analysis, coactive design modeling, and development of actionable HMI guidelines. I also mentored 3 undergraduates throughout.

---
{: data-content="hr with text"}
### Constraints:

- No access to proprietary AV data—relied on CDL manuals and public research
- 3-month timeline to complete research, synthesis, and deliverables
- Broad scope: HMI modes (visual, auditory, haptic) and automation levels (L2–L5)

---
{: data-content="hr with text"}
### What I Did:

1. **Defined Research Focus**
    Mapped key questions: What trucking tasks need humans? What HMI modes are underused?
2. **Mapped Research Gaps**
    Reviewed 100+ studies and created a matrix of automation level × HMI modality × task type
3. **Analyzed CDL Tasks**
    Used truck driver manuals to identify real-world tasks across driving, inspection, and planning
4. **Applied Coactive Design**
    Labeled tasks as fully automatable or requiring human input, and listed constraints (e.g., trust, legal)
5. **Developed HMI Guidelines**
    Proposed features like context-aware explanations (e.g., why a reroute happened) to boost transparency
6. **Mentored Research Team**
    Taught task analysis and synthesis skills while guiding report and presentation creation
7. **Delivered Multi-Audience Outputs**
    Created a written report, annotated bibliography, stakeholder-ready slides, and research matrices

---
{: data-content="hr with text"}

### Outcomes:
- Identified gaps in multimodal HMIs (most focus on visual-only systems)
- Highlighted where humans remain essential in L4 trucking (e.g., inspections, legal fallback)
- Proposed interface features to improve explainability and situational awareness
- Provided design takeaways that will guide our next simulation-based HMI prototypes

---
{: data-content="hr with text"}

### Tools & Frameworks:

- Coactive Design (for human-automation task mapping)
- CDL Task Extraction (for grounding user roles)
- Matrix Visualization (to spot HMI gaps)
- Literature Scoping (to map state of the field)

---
{: data-content="hr with text"}

### Publication: 

Coming soon..


